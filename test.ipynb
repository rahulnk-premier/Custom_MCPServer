{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5690e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = r\"E:\\rnakka\\Downloads\\ca.premierinc.goskope.crt\"\n",
    "os.environ['SSL_CERT_FILE'] = r\"E:\\rnakka\\Downloads\\ca.premierinc.goskope.crt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cece5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\rnakka\\\\Downloads\\\\ca.premierinc.goskope.crt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ['SSL_CERT_FILE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd83b9",
   "metadata": {},
   "source": [
    "Step1 : Fetching Data From Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17964251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching details for repository: PremierInc/fireball-sandbox...\n",
      "Successfully fetched details for PremierInc/fireball-sandbox.\n",
      "Fetching details for repository: PremierInc/fireball-shared-sandbox...\n",
      "No README.md found in fireball-shared-sandbox\n",
      "Successfully fetched details for PremierInc/fireball-shared-sandbox.\n",
      "Fetching details for repository: PremierInc/fireball-common-service...\n",
      "No README.md found in fireball-common-service\n",
      "Successfully fetched details for PremierInc/fireball-common-service.\n",
      "Fetching details for repository: PremierInc/fireball-pdfgen-app...\n",
      "No README.md found in fireball-pdfgen-app\n",
      "Successfully fetched details for PremierInc/fireball-pdfgen-app.\n",
      "Fetching details for repository: PremierInc/fireball-common-ui...\n",
      "Successfully fetched details for PremierInc/fireball-common-ui.\n",
      "Fetching details for repository: PremierInc/fireball-common-objects...\n",
      "No README.md found in fireball-common-objects\n",
      "Successfully fetched details for PremierInc/fireball-common-objects.\n",
      "Fetching details for repository: PremierInc/fireball-archetype...\n",
      "Successfully fetched details for PremierInc/fireball-archetype.\n",
      "Fetching details for repository: PremierInc/fireball-master-parent...\n",
      "No README.md found in fireball-master-parent\n",
      "Successfully fetched details for PremierInc/fireball-master-parent.\n",
      "Fetching details for repository: PremierInc/fireball-dashboard-parent...\n",
      "No README.md found in fireball-dashboard-parent\n",
      "Successfully fetched details for PremierInc/fireball-dashboard-parent.\n",
      "Fetching details for repository: PremierInc/fireball-firecat-demo...\n",
      "Successfully fetched details for PremierInc/fireball-firecat-demo.\n",
      "Fetching details for repository: PremierInc/fireball-playground...\n",
      "Successfully fetched details for PremierInc/fireball-playground.\n",
      "Fetching details for repository: PremierInc/fireball-rag-chatbot...\n",
      "No README.md found in fireball-rag-chatbot\n",
      "Successfully fetched details for PremierInc/fireball-rag-chatbot.\n",
      "\n",
      "Fetched data for 12 repositories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from github import Github, GithubException\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# --- Configuration ---\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\") # Recommended to use environment variables\n",
    "ORGANIZATION_NAME = \"PremierInc\"\n",
    "CERTIFICATE_PATH = r\"E:\\rnakka\\Downloads\\ca.premierinc.goskope.crt\"\n",
    "def get_all_repositories(g, org_name):\n",
    "    \"\"\"Fetches all repositories for a given GitHub organization.\"\"\"\n",
    "    try:\n",
    "        organization = g.get_organization(org_name)\n",
    "        return organization.get_repos()\n",
    "    except GithubException as e:\n",
    "        print(f\"Error fetching organization {org_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_repository_details(repo):\n",
    "    \"\"\"Extracts title, description, README, and recent commits from a repository.\"\"\"\n",
    "    repo_details = {\n",
    "        \"name\": repo.name,\n",
    "        \"title\": repo.full_name,\n",
    "        \"description\": repo.description or \"\",\n",
    "        \"readme\": \"\",\n",
    "        \"commits\": []\n",
    "    }\n",
    "\n",
    "    # Get README content\n",
    "    try:\n",
    "        readme_content = repo.get_contents(\"README.md\")\n",
    "        repo_details[\"readme\"] = readme_content.decoded_content.decode(\"utf-8\")\n",
    "    except GithubException:\n",
    "        print(f\"No README.md found in {repo.name}\")\n",
    "\n",
    "    # Get recent commit messages\n",
    "    try:\n",
    "        # --- FIX IS HERE ---\n",
    "        # Get a slice of the first 10 commits. This returns an iterable object.\n",
    "        recent_commits = repo.get_commits()[:10] \n",
    "        \n",
    "        # Now we can loop through this iterable object directly\n",
    "        for commit in recent_commits:\n",
    "            repo_details[\"commits\"].append(commit.commit.message)\n",
    "            \n",
    "    except GithubException as e:\n",
    "        print(f\"Could not fetch commits for {repo.name}: {e}\")\n",
    "\n",
    "    return repo_details\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not GITHUB_TOKEN:\n",
    "        print(\"Please set the GITHUB_TOKEN environment variable.\")\n",
    "    else:\n",
    "        g = Github(GITHUB_TOKEN,verify=CERTIFICATE_PATH)\n",
    "        repos = get_all_repositories(g, ORGANIZATION_NAME)\n",
    "        \n",
    "        all_repo_data = []\n",
    "        for repo in repos:\n",
    "            print(f\"Fetching details for repository: {repo.full_name}...\")\n",
    "            details = get_repository_details(repo)\n",
    "            all_repo_data.append(details)\n",
    "            print(f\"Successfully fetched details for {repo.full_name}.\")\n",
    "        \n",
    "        # At this point, `all_repo_data` holds the information for all your repos.\n",
    "        # The next step is to process and store this data.\n",
    "        print(f\"\\nFetched data for {len(all_repo_data)} repositories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acc0ca",
   "metadata": {},
   "source": [
    "Step 2 : Embeeding and Storing Data in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6adeb819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\rnakka\\Documents\\AI Agent\\mcp-agent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data processing and storage...\n",
      "Upserted a batch of 59 documents.\n",
      "\n",
      "Finished processing all repositories. Total documents in collection: 59\n",
      "Data indexing complete.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Configuration ---\n",
    "CHROMA_DB_PATH = \"./repo_db\"\n",
    "CHROMA_COLLECTION_NAME = \"github_repositories\"\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2' # A good starting model\n",
    "BATCH_SIZE = 100 # Process 100 documents at a time for scalability\n",
    "\n",
    "# --- Initialize ChromaDB and the Embedding Model ---\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=CHROMA_COLLECTION_NAME,\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    ")\n",
    "\n",
    "\n",
    "def process_and_store_data(repo_data):\n",
    "    \"\"\"\n",
    "    Processes repository data, creates embeddings, and stores them in ChromaDB using upsert and batching.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    def upsert_batch():\n",
    "        \"\"\"Helper function to upsert the current batch to ChromaDB.\"\"\"\n",
    "        if not documents:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        collection.upsert(\n",
    "            documents=documents,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        print(f\"Upserted a batch of {len(documents)} documents.\")\n",
    "        # Clear the lists for the next batch\n",
    "        documents.clear()\n",
    "        metadatas.clear()\n",
    "        ids.clear()\n",
    "\n",
    "\n",
    "    for repo in repo_data:\n",
    "        # 1. Title and Description\n",
    "        \n",
    "        if repo[\"title\"]:\n",
    "            text = f\"Repository: {repo['title']}\\nDescription: {repo['description']}\"\n",
    "            documents.append(text)\n",
    "            metadatas.append({\"repo_name\": repo[\"name\"], \"source\": \"description\"})\n",
    "            ids.append(f\"repo_{repo['name']}_desc\")\n",
    "\n",
    "        # 2. README (chunking it for better performance)\n",
    "        if repo[\"readme\"]:\n",
    "            # Simple chunking by paragraph\n",
    "            for i, chunk in enumerate(repo[\"readme\"].split(\"\\n\\n\")):\n",
    "                if chunk.strip():\n",
    "                    documents.append(chunk)\n",
    "                    metadatas.append({\"repo_name\": repo[\"name\"], \"source\": \"readme_chunk\"})\n",
    "                    ids.append(f\"repo_{repo['name']}_readme_{i}\")\n",
    "        \n",
    "        # 3. Commit Messages\n",
    "        if repo[\"commits\"]:\n",
    "            # Clean up commit messages (remove merge commits, etc.)\n",
    "            clean_commits = [msg.split('\\n')[0] for msg in repo[\"commits\"] if not msg.startswith('Merge pull request')]\n",
    "            commit_text = \"\\n\".join([f\"- {msg}\" for msg in clean_commits])\n",
    "            text = f\"Recent commit messages for {repo['title']}:\\n{commit_text}\"\n",
    "            documents.append(text)\n",
    "            metadatas.append({\"repo_name\": repo[\"name\"], \"source\": \"commits\"})\n",
    "            ids.append(f\"repo_{repo['name']}_commits\")\n",
    "            \n",
    "        # --- FIX 3: Check if it's time to process a batch ---\n",
    "        if len(documents) >= BATCH_SIZE:\n",
    "            upsert_batch()\n",
    "\n",
    "    # Process any remaining documents that didn't make a full batch\n",
    "    upsert_batch()\n",
    "    \n",
    "    print(f\"\\nFinished processing all repositories. Total documents in collection: {collection.count()}\")\n",
    "\n",
    "\n",
    "# --- To run this part, you would first get `all_repo_data` from Step 1 ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Starting data processing and storage...\")\n",
    "    process_and_store_data(all_repo_data)\n",
    "    print(\"Data indexing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71da3504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying for issue: 'I'm having trouble with the fireball application, particularly related to GridTable sort Icon alignment issue when column header has ellipses.'\n",
      "\n",
      "✅ The issue most likely belongs to the 'fireball-playground' repository.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Configuration ---\n",
    "CHROMA_DB_PATH = \"./repo_db\"\n",
    "CHROMA_COLLECTION_NAME = \"github_repositories\"\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
    "\n",
    "# --- Initialize ---\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "collection = client.get_collection(name=CHROMA_COLLECTION_NAME)\n",
    "\n",
    "def find_relevant_repo(issue_description, n_results=5): \n",
    "    \"\"\"\n",
    "    Finds the most relevant repository for a given issue description using similarity scores.\n",
    "    \"\"\"\n",
    "    # --- FIX 1: Explicitly embed the query with the same model used for indexing ---\n",
    "    query_embedding = model.encode(issue_description).tolist()\n",
    "\n",
    "    # Query using the embedding vector, not the text\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding], \n",
    "        n_results=n_results,\n",
    "        include=[\"metadatas\", \"distances\"] \n",
    "    )\n",
    "    \n",
    "    # Check for empty results\n",
    "    if not results or not results.get('ids')[0]:\n",
    "        return \"No relevant documents found in the database.\"\n",
    "\n",
    "    # --- FIX 2: Use similarity scores for a more accurate ranking ---\n",
    "    repo_scores = defaultdict(float)\n",
    "    \n",
    "    # results['distances'][0] is a list of distances corresponding to the results\n",
    "    # results['metadatas'][0] is a list of metadata dictionaries\n",
    "    for metadata, distance in zip(results['metadatas'][0], results['distances'][0]):\n",
    "        repo_name = metadata['repo_name']\n",
    "        \n",
    "        # Convert distance to a similarity score. For cosine, score = 1 - distance.\n",
    "        # A smaller distance means a higher score.\n",
    "        similarity_score = 1.0 - distance\n",
    "        \n",
    "        # Add the score to the repository's total\n",
    "        repo_scores[repo_name] += similarity_score\n",
    "        \n",
    "    if not repo_scores:\n",
    "        return \"No relevant repository found.\"\n",
    "\n",
    "    # Return the repository with the highest total score\n",
    "    most_relevant_repo = max(repo_scores, key=repo_scores.get)\n",
    "    return most_relevant_repo\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Example Query ---\n",
    "    issue = (\n",
    "        \"I'm having trouble with the fireball application, particularly related to \"\n",
    "        \"GridTable sort Icon alignment issue when column header has ellipses.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Querying for issue: '{issue}'\")\n",
    "    relevant_repo = find_relevant_repo(issue)\n",
    "    \n",
    "    if relevant_repo:\n",
    "        print(f\"\\n✅ The issue most likely belongs to the '{relevant_repo}' repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1ca4a",
   "metadata": {},
   "source": [
    "# Activity map to implement to understand retreival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54706f0",
   "metadata": {},
   "source": [
    "2. MCP Resource To connecct to copilot agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c14e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a7933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac81eff2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
